{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "import os\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>EthnicitySelf</th>\n",
       "      <th>GenderSelf</th>\n",
       "      <th>AgeSelf</th>\n",
       "      <th>AgeRated</th>\n",
       "      <th>FemaleProb</th>\n",
       "      <th>MaleProb</th>\n",
       "      <th>AsianProb</th>\n",
       "      <th>BlackProb</th>\n",
       "      <th>LatinoProb</th>\n",
       "      <th>...</th>\n",
       "      <th>UpperHeadLength</th>\n",
       "      <th>MidfaceLength</th>\n",
       "      <th>ChinLength</th>\n",
       "      <th>ForeheadHeight</th>\n",
       "      <th>CheekboneHeight</th>\n",
       "      <th>CheekboneProminence</th>\n",
       "      <th>FaceRoundness</th>\n",
       "      <th>fWHR1</th>\n",
       "      <th>fWHR2</th>\n",
       "      <th>RaterN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AF-200</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414099</td>\n",
       "      <td>0.326797</td>\n",
       "      <td>0.130719</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.388189</td>\n",
       "      <td>91.5</td>\n",
       "      <td>0.545752</td>\n",
       "      <td>1.921146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF-201</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414414</td>\n",
       "      <td>0.329279</td>\n",
       "      <td>0.144595</td>\n",
       "      <td>0.300901</td>\n",
       "      <td>0.383784</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.488288</td>\n",
       "      <td>1.901129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF-202</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.448276</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411080</td>\n",
       "      <td>0.310317</td>\n",
       "      <td>0.173424</td>\n",
       "      <td>0.298475</td>\n",
       "      <td>0.397029</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.481333</td>\n",
       "      <td>1.888249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AF-203</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.758621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354407</td>\n",
       "      <td>0.343793</td>\n",
       "      <td>0.169820</td>\n",
       "      <td>0.272266</td>\n",
       "      <td>0.421089</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.500231</td>\n",
       "      <td>1.863719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AF-204</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.137931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438931</td>\n",
       "      <td>0.293045</td>\n",
       "      <td>0.180237</td>\n",
       "      <td>0.293893</td>\n",
       "      <td>0.371925</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.513571</td>\n",
       "      <td>1.935783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AF-205</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.592593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408727</td>\n",
       "      <td>0.352182</td>\n",
       "      <td>0.158949</td>\n",
       "      <td>0.270481</td>\n",
       "      <td>0.408281</td>\n",
       "      <td>69.5</td>\n",
       "      <td>0.516919</td>\n",
       "      <td>1.718556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AF-206</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.523810</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383958</td>\n",
       "      <td>0.360228</td>\n",
       "      <td>0.172283</td>\n",
       "      <td>0.253916</td>\n",
       "      <td>0.399146</td>\n",
       "      <td>109.5</td>\n",
       "      <td>0.533935</td>\n",
       "      <td>1.847015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AF-207</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.413793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437947</td>\n",
       "      <td>0.273875</td>\n",
       "      <td>0.197728</td>\n",
       "      <td>0.329407</td>\n",
       "      <td>0.386201</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.553218</td>\n",
       "      <td>1.954528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AF-208</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.538462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428939</td>\n",
       "      <td>0.295835</td>\n",
       "      <td>0.214684</td>\n",
       "      <td>0.288751</td>\n",
       "      <td>0.382138</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.551739</td>\n",
       "      <td>2.053120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AF-209</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385501</td>\n",
       "      <td>0.326652</td>\n",
       "      <td>0.188913</td>\n",
       "      <td>0.267164</td>\n",
       "      <td>0.410235</td>\n",
       "      <td>122.5</td>\n",
       "      <td>0.455437</td>\n",
       "      <td>1.801707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model EthnicitySelf GenderSelf  AgeSelf   AgeRated  FemaleProb  MaleProb  \\\n",
       "0  AF-200             A          F      NaN  32.571429    1.000000  0.000000   \n",
       "1  AF-201             A          F      NaN  23.666667    1.000000  0.000000   \n",
       "2  AF-202             A          F      NaN  24.448276    0.827586  0.172414   \n",
       "3  AF-203             A          F      NaN  22.758621    1.000000  0.000000   \n",
       "4  AF-204             A          F      NaN  30.137931    1.000000  0.000000   \n",
       "5  AF-205             A          F      NaN  26.592593    1.000000  0.000000   \n",
       "6  AF-206             A          F      NaN  26.523810    0.857143  0.142857   \n",
       "7  AF-207             A          F      NaN  28.413793    1.000000  0.000000   \n",
       "8  AF-208             A          F      NaN  28.538462    1.000000  0.000000   \n",
       "9  AF-209             A          F      NaN  22.560000    1.000000  0.000000   \n",
       "\n",
       "   AsianProb  BlackProb  LatinoProb  ...  UpperHeadLength  MidfaceLength  \\\n",
       "0   1.000000   0.000000    0.000000  ...         0.414099       0.326797   \n",
       "1   0.962963   0.000000    0.000000  ...         0.414414       0.329279   \n",
       "2   0.310345   0.068966    0.137931  ...         0.411080       0.310317   \n",
       "3   0.758621   0.000000    0.068966  ...         0.354407       0.343793   \n",
       "4   0.827586   0.000000    0.068966  ...         0.438931       0.293045   \n",
       "5   0.846154   0.000000    0.000000  ...         0.408727       0.352182   \n",
       "6   1.000000   0.000000    0.000000  ...         0.383958       0.360228   \n",
       "7   0.035714   0.428571    0.035714  ...         0.437947       0.273875   \n",
       "8   0.230769   0.115385    0.384615  ...         0.428939       0.295835   \n",
       "9   0.080000   0.080000    0.400000  ...         0.385501       0.326652   \n",
       "\n",
       "   ChinLength  ForeheadHeight  CheekboneHeight  CheekboneProminence  \\\n",
       "0    0.130719        0.264706         0.388189                 91.5   \n",
       "1    0.144595        0.300901         0.383784                146.0   \n",
       "2    0.173424        0.298475         0.397029                 58.0   \n",
       "3    0.169820        0.272266         0.421089                 87.5   \n",
       "4    0.180237        0.293893         0.371925                 73.5   \n",
       "5    0.158949        0.270481         0.408281                 69.5   \n",
       "6    0.172283        0.253916         0.399146                109.5   \n",
       "7    0.197728        0.329407         0.386201                  3.0   \n",
       "8    0.214684        0.288751         0.382138                 50.0   \n",
       "9    0.188913        0.267164         0.410235                122.5   \n",
       "\n",
       "   FaceRoundness     fWHR1  fWHR2  RaterN  \n",
       "0       0.545752  1.921146    NaN      28  \n",
       "1       0.488288  1.901129    NaN      27  \n",
       "2       0.481333  1.888249    NaN      29  \n",
       "3       0.500231  1.863719    NaN      29  \n",
       "4       0.513571  1.935783    NaN      29  \n",
       "5       0.516919  1.718556    NaN      26  \n",
       "6       0.533935  1.847015    NaN      20  \n",
       "7       0.553218  1.954528    NaN      28  \n",
       "8       0.551739  2.053120    NaN      26  \n",
       "9       0.455437  1.801707    NaN      25  \n",
       "\n",
       "[10 rows x 98 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd_df_raw = pd.read_csv(\"CFD/metadata.csv\")\n",
    "cfd_df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileNames(target):\n",
    "    files = []\n",
    "    file_count = 0\n",
    "    path = \"CFD/Images/CFD/%s/\" % (target)\n",
    "    \n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if ('.jpg' in file) or ('.jpeg' in file) or ('.png' in file):\n",
    "                files.append(file)\n",
    "    return files\n",
    " \n",
    "cfd_df_raw[\"files\"] = cfd_df_raw.Model.apply(getFileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd_instances = []\n",
    "for index, instance in cfd_df_raw.iterrows():\n",
    "    folder = instance.Model\n",
    "    score = instance['Attractive']\n",
    "    for file in instance.files:\n",
    "        tmp_instance = []\n",
    "        tmp_instance.append(folder)\n",
    "        tmp_instance.append(file)\n",
    "        tmp_instance.append(score)\n",
    "        cfd_instances.append(tmp_instance)\n",
    " \n",
    "df = pd.DataFrame(cfd_instances, columns = [\"folder\", \"file\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrievePixels(path):\n",
    "    img = load_img(path, grayscale=False, target_size=(224, 224))\n",
    "    x = img_to_array(img).reshape(1, -1)[0]\n",
    "    return x\n",
    " \n",
    "df['exact_file'] = \"CFD/Images/CFD/\"+df[\"folder\"]+\"/\"+df['file']\n",
    "df['pixels'] = df['exact_file'].apply(retrievePixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findEmotion(file):\n",
    "    #sample file name CFD-WM-040-023-HO.jpg\n",
    "    file_name = file.split(\".\")[0] #[1] is jpg\n",
    "    emotion = file_name.split(\"-\")[4]\n",
    "    return emotion\n",
    " \n",
    "df['emotion'] = df.file.apply(findEmotion)\n",
    " \n",
    "#include neutral, happen open mouth and happy close mouth\n",
    "df = df[(df.emotion == 'N') | (df.emotion == 'HO') | (df.emotion == 'HC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "pixels = df['pixels'].values\n",
    "for i in range(0, pixels.shape[0]):\n",
    "    features.append(pixels[i])\n",
    " \n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 224, 224, 3)\n",
    " \n",
    "features = features / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y = train_test_split(features, df.score.values, test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Sequential()\n",
    "base_model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "base_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "base_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "base_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "base_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "base_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "base_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "base_model.add(Conv2D(4096, (7, 7), activation='relu'))\n",
    "base_model.add(Dropout(0.5))\n",
    "base_model.add(Conv2D(4096, (1, 1), activation='relu'))\n",
    "base_model.add(Dropout(0.5))\n",
    "base_model.add(Conv2D(2622, (1, 1)))\n",
    "base_model.add(Flatten())\n",
    "base_model.add(Activation('softmax'))\n",
    " \n",
    "#pre-trained weights of vgg-face model.\n",
    "#you can find it here: https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "#related blog post: https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/\n",
    "base_model.load_weights('vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = 1 #this is a regression problem\n",
    " \n",
    "#freeze all layers of VGG-Face except last 7 one\n",
    "for layer in base_model.layers[:-7]:\n",
    "    layer.trainable = False\n",
    " \n",
    "base_model_output = Sequential()\n",
    "base_model_output = Flatten()(base_model.layers[-4].output)\n",
    "base_model_output = Dense(num_of_classes)(base_model_output)\n",
    " \n",
    "attractiveness_model = Model(inputs=base_model.input, outputs=base_model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 4.8863 \n",
      "Epoch 00001: val_loss improved from inf to 0.67029, saving model to attractiveness.hdf5\n",
      "20/20 [==============================] - 386s 19s/step - loss: 4.8863 - val_loss: 0.6703\n",
      "Epoch 2/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7281 \n",
      "Epoch 00002: val_loss improved from 0.67029 to 0.45054, saving model to attractiveness.hdf5\n",
      "20/20 [==============================] - 429s 21s/step - loss: 0.7281 - val_loss: 0.4505\n",
      "Epoch 3/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4687 \n",
      "Epoch 00003: val_loss improved from 0.45054 to 0.34004, saving model to attractiveness.hdf5\n",
      "20/20 [==============================] - 407s 20s/step - loss: 0.4687 - val_loss: 0.3400\n",
      "Epoch 4/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4165 \n",
      "Epoch 00004: val_loss did not improve from 0.34004\n",
      "20/20 [==============================] - 466s 23s/step - loss: 0.4165 - val_loss: 0.3481\n",
      "Epoch 5/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.3474 \n",
      "Epoch 00005: val_loss did not improve from 0.34004\n",
      "20/20 [==============================] - 387s 19s/step - loss: 0.3474 - val_loss: 0.4083\n",
      "Epoch 6/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2887 \n",
      "Epoch 00006: val_loss improved from 0.34004 to 0.33172, saving model to attractiveness.hdf5\n",
      "20/20 [==============================] - 403s 20s/step - loss: 0.2887 - val_loss: 0.3317\n",
      "Epoch 7/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2891 \n",
      "Epoch 00007: val_loss improved from 0.33172 to 0.28627, saving model to attractiveness.hdf5\n",
      "20/20 [==============================] - 516s 26s/step - loss: 0.2891 - val_loss: 0.2863\n",
      "Epoch 8/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2599 \n",
      "Epoch 00008: val_loss did not improve from 0.28627\n",
      "20/20 [==============================] - 1027s 51s/step - loss: 0.2599 - val_loss: 0.3434\n",
      "Epoch 9/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2576 \n",
      "Epoch 00009: val_loss improved from 0.28627 to 0.28228, saving model to attractiveness.hdf5\n",
      "20/20 [==============================] - 432s 22s/step - loss: 0.2576 - val_loss: 0.2823\n",
      "Epoch 10/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2212 \n",
      "Epoch 00010: val_loss did not improve from 0.28228\n",
      "20/20 [==============================] - 439s 22s/step - loss: 0.2212 - val_loss: 0.2833\n",
      "Epoch 11/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2254 \n",
      "Epoch 00011: val_loss improved from 0.28228 to 0.26585, saving model to attractiveness.hdf5\n",
      "20/20 [==============================] - 387s 19s/step - loss: 0.2254 - val_loss: 0.2659\n",
      "Epoch 12/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2284 \n",
      "Epoch 00012: val_loss did not improve from 0.26585\n",
      "20/20 [==============================] - 443s 22s/step - loss: 0.2284 - val_loss: 0.2798\n",
      "Epoch 13/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2229 \n",
      "Epoch 00013: val_loss improved from 0.26585 to 0.25180, saving model to attractiveness.hdf5\n",
      "20/20 [==============================] - 386s 19s/step - loss: 0.2229 - val_loss: 0.2518\n",
      "Epoch 14/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2006 \n",
      "Epoch 00014: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 367s 18s/step - loss: 0.2006 - val_loss: 0.2651\n",
      "Epoch 15/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2069 \n",
      "Epoch 00015: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 374s 19s/step - loss: 0.2069 - val_loss: 0.2634\n",
      "Epoch 16/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1952 \n",
      "Epoch 00016: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 382s 19s/step - loss: 0.1952 - val_loss: 0.2817\n",
      "Epoch 17/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2081 \n",
      "Epoch 00017: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 375s 19s/step - loss: 0.2081 - val_loss: 0.2603\n",
      "Epoch 18/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1923 \n",
      "Epoch 00018: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 375s 19s/step - loss: 0.1923 - val_loss: 0.2546\n",
      "Epoch 19/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2039 \n",
      "Epoch 00019: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 371s 19s/step - loss: 0.2039 - val_loss: 0.2893\n",
      "Epoch 20/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2170 \n",
      "Epoch 00020: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 490s 24s/step - loss: 0.2170 - val_loss: 0.2619\n",
      "Epoch 21/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2122 \n",
      "Epoch 00021: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 471s 24s/step - loss: 0.2122 - val_loss: 0.2648\n",
      "Epoch 22/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1833 \n",
      "Epoch 00022: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 661s 33s/step - loss: 0.1833 - val_loss: 0.2562\n",
      "Epoch 23/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1700 \n",
      "Epoch 00023: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 12676s 634s/step - loss: 0.1700 - val_loss: 0.2662\n",
      "Epoch 24/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1571 \n",
      "Epoch 00024: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 1151s 58s/step - loss: 0.1571 - val_loss: 0.2673\n",
      "Epoch 25/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2029 \n",
      "Epoch 00025: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 1273s 64s/step - loss: 0.2029 - val_loss: 0.2744\n",
      "Epoch 26/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2815 \n",
      "Epoch 00026: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 917s 46s/step - loss: 0.2815 - val_loss: 0.2648\n",
      "Epoch 27/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1894 \n",
      "Epoch 00027: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 1297s 65s/step - loss: 0.1894 - val_loss: 0.2632\n",
      "Epoch 28/5000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2175 \n",
      "Epoch 00028: val_loss did not improve from 0.25180\n",
      "20/20 [==============================] - 770s 39s/step - loss: 0.2175 - val_loss: 0.3314\n",
      "Epoch 29/5000\n",
      " 6/20 [========>.....................] - ETA: 6:40 - loss: 0.2575"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "attractiveness_model.compile(loss='mean_squared_error'\n",
    ", optimizer=keras.optimizers.Adam())\n",
    " \n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='attractiveness.hdf5'\n",
    "    , monitor = \"val_loss\", verbose=1\n",
    ", save_best_only=True, mode = 'auto'\n",
    ")\n",
    " \n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    " \n",
    "score = attractiveness_model.fit(train_x, train_y, epochs=5000\n",
    "    , validation_data=(val_x, val_y), callbacks=[checkpointer, earlyStop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
